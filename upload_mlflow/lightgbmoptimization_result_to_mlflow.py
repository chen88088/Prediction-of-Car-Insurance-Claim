import os 
import sys
import pandas as pd
import mlflow
import glob
import shutil
import yaml

experiment_name = sys.argv[1]
experiment_run_name = sys.argv[2]

reserved_run_id = None
output_dir = None

if len(sys.argv) >= 4:
    reserved_run_id = sys.argv[3]
if len(sys.argv) >= 5:
    output_dir = os.path.abspath(sys.argv[4])
    if not os.path.exists(output_dir):
        raise FileNotFoundError(f"âŒ æŒ‡å®šçš„ output_dir ä¸å­˜åœ¨ï¼š{output_dir}")

# åˆ¤æ–·æ˜¯å¦åœ¨å®¹å™¨ä¸­ï¼ˆæœªä¾† K8sï¼‰æˆ–æœ¬åœ°åŸ·è¡Œ
# âœ… å–ä»£åŸæœ¬é€™æ®µ
if os.getcwd().startswith("/mnt/storage/") and "CODE" in os.getcwd():
    job_root_dir = os.path.abspath(os.path.join(os.getcwd(),  ".."))  # âœ… è·³å‡º CODE/upload_mlflow
    working_dir = os.path.join(job_root_dir, "OUTPUT")
    config_path = os.path.join(job_root_dir, "CONFIG", "config.yaml")
else:
    script_dir = os.path.dirname(os.path.abspath(__file__))
    working_dir = os.path.abspath(os.path.join(script_dir, "..", "..", "OUTPUT"))
    config_path = os.path.abspath(os.path.join(script_dir, "..", "..", "CONFIG", "config.yaml"))

# è‹¥æœ‰æ‰‹å‹•æŒ‡å®š output_dir å‰‡ä½¿ç”¨ï¼Œå¦å‰‡æŠ“æœ€æ–°
output_dir = None
if len(sys.argv) >= 4:
    output_dir = os.path.abspath(sys.argv[3])
    if not os.path.exists(output_dir):
        raise FileNotFoundError(f"âŒ æŒ‡å®šçš„ output_dir ä¸å­˜åœ¨ï¼š{output_dir}")
else:
    print(f"ğŸ” è‡ªå‹•æ¨¡å¼ï¼šåˆ—å‡º {working_dir} ä¸‹æ‰€æœ‰è³‡æ–™å¤¾...")
    all_dirs = [f for f in os.listdir(working_dir) if os.path.isdir(os.path.join(working_dir, f))]
    lightgbm_dirs = [d for d in all_dirs if d.startswith("lightgbmoptimization_20")]
    print("âœ… å¯ç”¨çš„è³‡æ–™å¤¾ï¼š", lightgbm_dirs)
    if not lightgbm_dirs:
        raise FileNotFoundError("âŒ æ‰¾ä¸åˆ°ä»»ä½• lightgbmoptimization_20* è³‡æ–™å¤¾")
    output_dir = os.path.join(working_dir, sorted(lightgbm_dirs, reverse=True)[0])

print(f"\nğŸ“‚ ä½¿ç”¨çš„è¼¸å‡ºè³‡æ–™å¤¾ï¼š{output_dir}")

# è¨­å®š MLflow èˆ‡ MinIO
os.environ["MLFLOW_TRACKING_URI"] = "http://10.52.52.142:5000"
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://10.52.52.142:9000"
os.environ["AWS_ACCESS_KEY_ID"] = "minio"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"

mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI"))
mlflow.set_experiment(experiment_name)

# === å•Ÿå‹• MLflow run ===
if reserved_run_id:
    print(f"ä½¿ç”¨ reserved run_id: {reserved_run_id}")
    mlflow.start_run(run_id=reserved_run_id)
else:
    print(f"æ–°å»ºä¸€å€‹ runï¼š{experiment_run_name}")
    mlflow.start_run(run_name=experiment_run_name)


    
# ä¸Šå‚³ metrics
metrics_path = os.path.join(output_dir, "metrics.json")
if os.path.exists(metrics_path):
    metrics = pd.read_json(metrics_path, typ="series")
    for k, v in metrics.items():
        mlflow.log_metric(k, float(v))

# ä¸Šå‚³æ¯è¼ª AUCï¼ˆevals_resultï¼‰
eval_path = os.path.join(output_dir, "evals_result.json")
if os.path.exists(eval_path):
    evals = pd.read_json(eval_path)
    if "valid" in evals and "auc" in evals["valid"]:
        for i, auc in enumerate(evals["valid"]["auc"]):
            mlflow.log_metric("roc_auc_iter", auc, step=i)

# ä¸Šå‚³å ±å‘Šèˆ‡åœ–è¡¨
for fname in ["optimized_lgbm_report.json", "optimized_feature_importance.png", "optimized_roc_curve.png"]:
    full_path = os.path.join(output_dir, fname)
    if os.path.exists(full_path):
        mlflow.log_artifact(full_path)

# âœ… ä¸Šå‚³ç•¶ä¸‹ä½¿ç”¨çš„åƒæ•¸ config.yaml ä½œç‚º artifact + MLflow params
if os.path.exists(config_path):
    copied_config_path = os.path.join("/tmp", f"used_config_{experiment_run_name}.yaml")  # âœ… å®‰å…¨ï¼Œæ‰€æœ‰äººå¯å¯«

    shutil.copyfile(config_path, copied_config_path)
    mlflow.log_artifact(copied_config_path)

    with open(config_path, "r") as f:
        config_data = yaml.safe_load(f)
        if "params" in config_data:
            for key, value in config_data["params"].items():
                mlflow.log_param(key, value)
# === å®Œæˆä¸Šå‚³ï¼ŒçµæŸ run ===
mlflow.end_run()
print(f"\nâœ… å·²ä¸Šå‚³æ‰€æœ‰çµæœèˆ‡ config è‡³ MLflowï¼š{experiment_run_name}")
